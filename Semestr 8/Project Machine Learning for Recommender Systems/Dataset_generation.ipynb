{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVcj8tKxI3pS",
        "outputId": "47759397-e276-4aa4-a270-5c8f294770ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 36.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 40.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 51 kB 28.9 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 61 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 71 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 81 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 92 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 102 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 112 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 122 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 133 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 143 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 153 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 163 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 174 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 184 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 194 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 204 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 215 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 225 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 235 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 245 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 256 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 266 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 276 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 286 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 296 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 307 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 317 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 327 kB 35.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 335 kB 35.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 70.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 310 kB 60.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 32.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 12.4 MB 35.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 53.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 197 kB 56.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 749 kB 44.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 386 kB 41.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 38.3 MB/s \n",
            "\u001b[?25h  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install recommenders recommenders[examples] tf_slim --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import recommenders\n",
        "import recommenders.datasets.movielens\n",
        "from recommenders.models.ncf.ncf_singlenode import NCF\n",
        "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
        "from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "from recommenders.datasets.python_splitters import python_chrono_split\n",
        "from recommenders.utils.timer import Timer\n",
        "\n",
        "from tqdm import tqdm\n",
        "import sklearn.utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "WqMUTm9ZJYSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random split\n",
        "RandomDatasetCreator ensures that every item and user is present at least once in the training set."
      ],
      "metadata": {
        "id": "j4-qUpwJdOag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomDatasetCreator:\n",
        "    def __init__(self, df, user_id=\"userID\", item_id=\"itemID\", rating=\"rating\", shuffle=True, copy=False, seed=42):\n",
        "        self.seed = seed\n",
        "        if seed is not None:\n",
        "            random.seed(self.seed)\n",
        "            np.random.seed(seed=self.seed)\n",
        "        if shuffle:\n",
        "            self.df = sklearn.utils.shuffle(df, random_state=self.seed)\n",
        "        else:\n",
        "            self.df = df\n",
        "        if copy:\n",
        "            self.df = self.df.copy()\n",
        "        self.user_id = user_id\n",
        "        self.item_id = item_id\n",
        "        self.rating = rating\n",
        "        self.n_users, self.n_items = self.df[self.user_id].nunique(), self.df[self.item_id].nunique()\n",
        "        self.n_max_ratings = self.n_users * self.n_items\n",
        "        self.n_ratings = self.df.shape[0]\n",
        "        self.max_sparsity = self.n_ratings / self.n_max_ratings\n",
        "        self.minimal_indexes = self.__get_minimal_indexes()\n",
        "        self.min_sparsity = self.minimal_indexes.shape[0] / self.n_max_ratings\n",
        "        self.minimal_df = self.df.loc[self.minimal_indexes]\n",
        "        self.remaining_df = self.df[~self.df.index.isin(self.minimal_indexes)]\n",
        "\n",
        "    def __get_minimal_indexes(self):\n",
        "        if \"index\" in self.df.columns:\n",
        "            raise Exception(\"Dataframe can not contain 'index' column name.\")\n",
        "        df_with_index_as_column = self.df.reset_index()\n",
        "        numpy_array_of_indexes = pd.concat([df_with_index_as_column.groupby(self.user_id).first()[\"index\"],\n",
        "                   df_with_index_as_column.groupby(self.item_id).first()[\"index\"]]).unique()\n",
        "        return numpy_array_of_indexes\n",
        "\n",
        "    def train_test_split(self, train_size=0.8):\n",
        "        sparsity = self.max_sparsity * train_size\n",
        "        if sparsity <= self.min_sparsity:\n",
        "            return self.minimal_df.copy()\n",
        "        if sparsity >= self.max_sparsity:\n",
        "            return self.df\n",
        "        num_of_additional_ratings = max(int(train_size * self.n_ratings) - self.minimal_indexes.shape[0], 0)\n",
        "        additional_df = self.remaining_df.sample(n=num_of_additional_ratings)\n",
        "        train_df = pd.concat([self.minimal_df, additional_df])\n",
        "        test_df = self.df[~self.df.index.isin(train_df.index)]\n",
        "        return train_df, test_df"
      ],
      "metadata": {
        "id": "jzuPFcGFJYXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = recommenders.datasets.movielens.load_pandas_df('100k', ('userID', 'itemID', 'rating'))\n",
        "dataset_generator = RandomDatasetCreator(df)\n",
        "train_df, test_df = dataset_generator.train_test_split(0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUEUsCMhJYaQ",
        "outputId": "27547b92-e2d6-4a63-8915-2d3d5a9d2613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 8.49kKB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time split\n",
        "Some of the users or items might not be present in the training set."
      ],
      "metadata": {
        "id": "vl1apAnydlpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = recommenders.datasets.movielens.load_pandas_df('100k', ('userID', 'itemID', 'ratings', 'timestamp'))\n",
        "random.seed(42)\n",
        "np.random.seed(seed=42)\n",
        "train_df, test_df = python_chrono_split(df, ratio=0.8, col_user='userID', col_item='itemID', col_timestamp='timestamp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkFgB20Jd03C",
        "outputId": "ba911174-9e54-4967-8a08-b6f50c625496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 13.3kKB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leave-one-out user\n",
        "LeaveOneOutUser ensures that every item and user is present at least once in the training set."
      ],
      "metadata": {
        "id": "c17cMyPfya6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeaveOneOutUser:\n",
        "    def __init__(self, df, user_id=\"userID\", item_id=\"itemID\", rating=\"rating\", timestamp=\"timestamp\", shuffle=True, copy=False, seed=42):\n",
        "        self.seed = seed\n",
        "        if seed is not None:\n",
        "            random.seed(self.seed)\n",
        "            np.random.seed(seed=self.seed)\n",
        "        if shuffle:\n",
        "            self.df = sklearn.utils.shuffle(df, random_state=self.seed)\n",
        "        else:\n",
        "            self.df = df\n",
        "        self.df = self.df.sort_values(timestamp)\n",
        "        if copy:\n",
        "            self.df = self.df.copy()\n",
        "        self.user_id = user_id\n",
        "        self.item_id = item_id\n",
        "        self.rating = rating\n",
        "        self.timestamp = timestamp\n",
        "        self.n_users, self.n_items = self.df[self.user_id].nunique(), self.df[self.item_id].nunique()\n",
        "        self.n_max_ratings = self.n_users * self.n_items\n",
        "        self.n_ratings = self.df.shape[0]\n",
        "        self.max_sparsity = self.n_ratings / self.n_max_ratings\n",
        "        self.minimal_indexes = self.__get_minimal_indexes()\n",
        "        self.min_sparsity = self.minimal_indexes.shape[0] / self.n_max_ratings\n",
        "        self.minimal_df = self.df.loc[self.minimal_indexes]\n",
        "        self.remaining_df = self.df[~self.df.index.isin(self.minimal_indexes)]\n",
        "\n",
        "    def __get_minimal_indexes(self):\n",
        "        if \"index\" in self.df.columns:\n",
        "            raise Exception(\"Dataframe can not contain 'index' column name.\")\n",
        "        df_with_index_as_column = self.df.reset_index()\n",
        "        numpy_array_of_indexes = pd.concat([df_with_index_as_column.groupby(self.user_id).first()[\"index\"],\n",
        "                   df_with_index_as_column.groupby(self.item_id).first()[\"index\"]]).unique()\n",
        "        return numpy_array_of_indexes\n",
        "\n",
        "    def train_test_split(self):\n",
        "        test_df = self.remaining_df.sort_values(self.timestamp).reset_index().groupby(self.user_id).last().reset_index()\n",
        "        test_df = test_df.set_index('index')\n",
        "        test_df.index.name = None\n",
        "        train_df = self.df[~self.df.index.isin(test_df.index)]\n",
        "        return train_df, test_df"
      ],
      "metadata": {
        "id": "Ck0gIwMhyT5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = recommenders.datasets.movielens.load_pandas_df('100k', ('userID', 'itemID', 'rating', 'timestamp'))\n",
        "dataset_generator = LeaveOneOutUser(df)\n",
        "train_df, test_df = dataset_generator.train_test_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdRVWQdZ0rfQ",
        "outputId": "56daaa6a-aa99-4224-9b22-73b6c37abfa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 18.9kKB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leave-one-out item\n",
        "LeaveOneOutUser ensures that every item and user is present at least once in the training set."
      ],
      "metadata": {
        "id": "ExJrQkBfHA-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeaveOneOutItem:\n",
        "    def __init__(self, df, user_id=\"userID\", item_id=\"itemID\", rating=\"rating\", timestamp=\"timestamp\", shuffle=True, copy=False, seed=42):\n",
        "        self.seed = seed\n",
        "        if seed is not None:\n",
        "            random.seed(self.seed)\n",
        "            np.random.seed(seed=self.seed)\n",
        "        if shuffle:\n",
        "            self.df = sklearn.utils.shuffle(df, random_state=self.seed)\n",
        "        else:\n",
        "            self.df = df\n",
        "        self.df = self.df.sort_values(timestamp)\n",
        "        if copy:\n",
        "            self.df = self.df.copy()\n",
        "        self.user_id = user_id\n",
        "        self.item_id = item_id\n",
        "        self.rating = rating\n",
        "        self.timestamp = timestamp\n",
        "        self.n_users, self.n_items = self.df[self.user_id].nunique(), self.df[self.item_id].nunique()\n",
        "        self.n_max_ratings = self.n_users * self.n_items\n",
        "        self.n_ratings = self.df.shape[0]\n",
        "        self.max_sparsity = self.n_ratings / self.n_max_ratings\n",
        "        self.minimal_indexes = self.__get_minimal_indexes()\n",
        "        self.min_sparsity = self.minimal_indexes.shape[0] / self.n_max_ratings\n",
        "        self.minimal_df = self.df.loc[self.minimal_indexes]\n",
        "        self.remaining_df = self.df[~self.df.index.isin(self.minimal_indexes)]\n",
        "\n",
        "    def __get_minimal_indexes(self):\n",
        "        if \"index\" in self.df.columns:\n",
        "            raise Exception(\"Dataframe can not contain 'index' column name.\")\n",
        "        df_with_index_as_column = self.df.reset_index()\n",
        "        numpy_array_of_indexes = pd.concat([df_with_index_as_column.groupby(self.user_id).first()[\"index\"],\n",
        "                   df_with_index_as_column.groupby(self.item_id).first()[\"index\"]]).unique()\n",
        "        return numpy_array_of_indexes\n",
        "\n",
        "    def train_test_split(self):\n",
        "        test_df = self.remaining_df.sort_values(self.timestamp).reset_index().groupby(self.item_id).last().reset_index()\n",
        "        test_df = test_df.set_index('index')\n",
        "        test_df.index.name = None\n",
        "        train_df = self.df[~self.df.index.isin(test_df.index)]\n",
        "        return train_df, test_df"
      ],
      "metadata": {
        "id": "wQ0ACgX7HBPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = recommenders.datasets.movielens.load_pandas_df('100k', ('userID', 'itemID', 'rating', 'timestamp'))\n",
        "dataset_generator = LeaveOneOutItem(df)\n",
        "train_df, test_df = dataset_generator.train_test_split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFZistElHCDJ",
        "outputId": "df4ce9f6-37b1-4971-f23f-741f8c21f55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:recommenders.datasets.download_utils:Downloading https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "100%|██████████| 4.81k/4.81k [00:00<00:00, 21.2kKB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving dataset to file\n",
        "To save the dataset to files use use the code below:"
      ],
      "metadata": {
        "id": "0Uhn6_9mWsgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_FILE_PATH = \"./train.csv\"\n",
        "TEST_FILE_PATH = \"./test.csv\"\n",
        "\n",
        "train_df.sort_values(\"userID\").to_csv(TRAIN_FILE_PATH, index=False)\n",
        "test_df.sort_values(\"userID\").to_csv(TEST_FILE_PATH, index=False)"
      ],
      "metadata": {
        "id": "Y7Lp7Nh9XETP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libffm format\n",
        "If your model requires input in Libffm format you can use [recommenders LibffmConverter](https://microsoft-recommenders.readthedocs.io/en/latest/datasets.html#recommenders.datasets.pandas_df_utils.LibffmConverter):"
      ],
      "metadata": {
        "id": "fzwfn94uWqUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from recommenders.datasets.pandas_df_utils import LibffmConverter\n",
        "\n",
        "converter = LibffmConverter()\n",
        "converter = converter.fit(train_df, col_rating='rating')\n",
        "limffm_train_df = converter.transform(train_df)\n",
        "\n",
        "converter = converter.fit(test_df, col_rating='rating')\n",
        "limffm_test_df = converter.transform(test_df)\n",
        "limffm_test_df"
      ],
      "metadata": {
        "id": "Extb5QkXVzui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIrzu5hP-wic"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}